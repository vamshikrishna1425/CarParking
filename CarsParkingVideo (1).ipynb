{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "388234da"
      },
      "outputs": [],
      "source": [
        "import os"
      ],
      "id": "388234da"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ba4ab3eb"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'ssd_mobilenet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "id": "ba4ab3eb"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "14fbafac"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\n",
        "    'TRAIN': os.path.join('Tensorflow', 'workspace','images','train'),\n",
        "    'TEST': os.path.join('Tensorflow', 'workspace','images','test'),\n",
        " }\n"
      ],
      "id": "14fbafac"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e04602cd"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}\n"
      ],
      "id": "e04602cd"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a5672608"
      },
      "outputs": [],
      "source": [
        "\n",
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}\n"
      ],
      "id": "a5672608"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "41f9aef3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget\n"
      ],
      "id": "41f9aef3"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67f6e79",
        "outputId": "695e105b-f968-4670-83f6-83b8369382ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 79485, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 79485 (delta 86), reused 140 (delta 62), pack-reused 79301\u001b[K\n",
            "Receiving objects: 100% (79485/79485), 593.99 MiB | 40.24 MiB/s, done.\n",
            "Resolving deltas: 100% (56542/56542), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}\n"
      ],
      "id": "d67f6e79"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2c813fe",
        "outputId": "3a6fd279-a8d7-418c-dc6f-ee03a6f5ee8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 96.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.0-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 62.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.28.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 91.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow~=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 21 kB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 88.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 71.7 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 83.6 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp38-cp38-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 69.7 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[K     |████████████████████████████████| 662 kB 80.5 MB/s \n",
            "\u001b[?25hCollecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.57.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.28.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.51.1)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting keras\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 78.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 78.3 MB/s \n",
            "\u001b[?25hCollecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 57.8 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=2.2.0\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 79.4 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[K     |████████████████████████████████| 278 kB 103.0 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[K     |████████████████████████████████| 526 kB 91.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting objsize<0.6.0,>=0.5.2\n",
            "  Downloading objsize-0.5.2-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.11.0)\n",
            "Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696518 sha256=80a5b6c052a3135808d0fd4392d97355a1d335713e0de3823496ba71dc6d0bdc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v3pqx187/wheels/5f/a2/bd/4f7680f297994e5417be0c4494525a7f286ebe68fc40f4ac38\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=b52d27288b76aaca07f669d55a4b51dcbc9154227f1b56d7c586112e75cf74ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=fede9ed2f30c7f0d620a1801dbccca8cbfb3bc30eebb032a5341f7bec1dc0f8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=60527febb22ca3b4b46084f8c8979cb2bbb61cb741831ee3e8c5857a528611a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=7985ff3f20792bb41deb8bd7740b9d08ca78eda22d043ecf040b4285c004398c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built object-detection dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, orjson, opencv-python-headless, objsize, immutabledict, hdfs, fasteners, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed apache-beam-2.43.0 avro-python3-1.10.2 cloudpickle-2.2.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 flatbuffers-22.12.6 hdfs-2.7.0 immutabledict-2.2.3 keras-2.11.0 lvis-0.5.3 object-detection-0.1 objsize-0.5.2 opencv-python-headless-4.5.2.52 orjson-3.8.3 portalocker-2.6.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.11.0 tensorflow-io-0.28.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tf-models-official-2.11.0 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ],
      "id": "b2c813fe"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32614dcb",
        "outputId": "7e8aca5d-08f6-4cfa-a8a4-1070278e798e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 02:39:59.946177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-08 02:40:00.089175: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-12-08 02:40:00.902244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:40:00.902439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:40:00.902462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "Running tests under Python 3.8.15: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-12-08 02:40:05.626378: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-12-08 02:40:05.626461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "W1208 02:40:05.912345 140718506006400 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.51s\n",
            "I1208 02:40:06.225605 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.51s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.69s\n",
            "I1208 02:40:06.919297 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.69s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
            "I1208 02:40:07.224251 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.28s\n",
            "I1208 02:40:07.506951 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.23s\n",
            "I1208 02:40:09.741362 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.23s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1208 02:40:09.747464 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1208 02:40:09.773881 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1208 02:40:09.791491 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1208 02:40:09.810371 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.27s\n",
            "I1208 02:40:10.077606 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "I1208 02:40:10.185287 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "I1208 02:40:10.293835 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I1208 02:40:10.401479 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I1208 02:40:10.502887 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I1208 02:40:10.534183 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1208 02:40:10.726209 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1208 02:40:10.726382 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I1208 02:40:10.726460 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I1208 02:40:10.728841 140718506006400 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1208 02:40:10.757861 140718506006400 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1208 02:40:10.757988 140718506006400 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1208 02:40:10.831735 140718506006400 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1208 02:40:10.831874 140718506006400 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1208 02:40:11.020461 140718506006400 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1208 02:40:11.020623 140718506006400 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1208 02:40:11.204043 140718506006400 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1208 02:40:11.204214 140718506006400 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1208 02:40:11.469354 140718506006400 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1208 02:40:11.469522 140718506006400 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1208 02:40:11.733587 140718506006400 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1208 02:40:11.733744 140718506006400 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1208 02:40:12.082746 140718506006400 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1208 02:40:12.082911 140718506006400 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1208 02:40:12.169913 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1208 02:40:12.210581 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:12.264808 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1208 02:40:12.264954 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1208 02:40:12.265011 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I1208 02:40:12.266687 140718506006400 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1208 02:40:12.283860 140718506006400 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1208 02:40:12.283965 140718506006400 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1208 02:40:12.424192 140718506006400 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1208 02:40:12.424341 140718506006400 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1208 02:40:12.681102 140718506006400 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1208 02:40:12.681273 140718506006400 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1208 02:40:12.941782 140718506006400 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1208 02:40:12.941944 140718506006400 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1208 02:40:13.288850 140718506006400 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1208 02:40:13.289011 140718506006400 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1208 02:40:13.632628 140718506006400 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1208 02:40:13.632790 140718506006400 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1208 02:40:14.063679 140718506006400 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1208 02:40:14.063837 140718506006400 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1208 02:40:14.246192 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1208 02:40:14.280315 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:14.341113 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1208 02:40:14.341268 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I1208 02:40:14.341325 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I1208 02:40:14.342976 140718506006400 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1208 02:40:14.360140 140718506006400 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1208 02:40:14.360259 140718506006400 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1208 02:40:14.493398 140718506006400 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1208 02:40:14.493538 140718506006400 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1208 02:40:14.752572 140718506006400 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1208 02:40:14.752734 140718506006400 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1208 02:40:15.196441 140718506006400 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1208 02:40:15.196607 140718506006400 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1208 02:40:15.557386 140718506006400 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1208 02:40:15.557557 140718506006400 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1208 02:40:15.912117 140718506006400 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1208 02:40:15.912295 140718506006400 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1208 02:40:16.363078 140718506006400 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1208 02:40:16.363264 140718506006400 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1208 02:40:16.547661 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1208 02:40:16.585227 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:16.646008 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1208 02:40:16.646163 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I1208 02:40:16.646224 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I1208 02:40:16.647897 140718506006400 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1208 02:40:16.667925 140718506006400 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1208 02:40:16.668045 140718506006400 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1208 02:40:16.815925 140718506006400 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1208 02:40:16.816074 140718506006400 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1208 02:40:17.082378 140718506006400 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1208 02:40:17.082544 140718506006400 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1208 02:40:17.348121 140718506006400 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1208 02:40:17.348296 140718506006400 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1208 02:40:17.790834 140718506006400 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1208 02:40:17.790993 140718506006400 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1208 02:40:18.235009 140718506006400 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1208 02:40:18.235181 140718506006400 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1208 02:40:18.769007 140718506006400 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1208 02:40:18.769181 140718506006400 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1208 02:40:18.952804 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1208 02:40:18.992239 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:19.059676 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1208 02:40:19.059819 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I1208 02:40:19.059877 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I1208 02:40:19.061554 140718506006400 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1208 02:40:19.080996 140718506006400 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1208 02:40:19.081115 140718506006400 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1208 02:40:19.223854 140718506006400 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1208 02:40:19.224001 140718506006400 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1208 02:40:19.564531 140718506006400 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1208 02:40:19.564685 140718506006400 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1208 02:40:19.919278 140718506006400 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1208 02:40:19.919437 140718506006400 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1208 02:40:20.432929 140718506006400 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1208 02:40:20.433093 140718506006400 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1208 02:40:20.955016 140718506006400 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1208 02:40:20.955188 140718506006400 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1208 02:40:21.854860 140718506006400 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1208 02:40:21.855019 140718506006400 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1208 02:40:22.038216 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1208 02:40:22.074885 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:22.150665 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1208 02:40:22.150826 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I1208 02:40:22.150913 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I1208 02:40:22.152626 140718506006400 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1208 02:40:22.170544 140718506006400 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1208 02:40:22.170660 140718506006400 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1208 02:40:22.374675 140718506006400 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1208 02:40:22.374827 140718506006400 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1208 02:40:22.799352 140718506006400 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1208 02:40:22.799523 140718506006400 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1208 02:40:23.239374 140718506006400 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1208 02:40:23.239542 140718506006400 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1208 02:40:23.854277 140718506006400 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1208 02:40:23.854437 140718506006400 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1208 02:40:24.474357 140718506006400 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1208 02:40:24.474532 140718506006400 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1208 02:40:25.252224 140718506006400 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1208 02:40:25.252386 140718506006400 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1208 02:40:25.524796 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1208 02:40:25.561891 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:25.647639 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1208 02:40:25.647785 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1208 02:40:25.647842 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I1208 02:40:25.649498 140718506006400 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1208 02:40:25.668230 140718506006400 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1208 02:40:25.668339 140718506006400 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1208 02:40:25.876641 140718506006400 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1208 02:40:25.876790 140718506006400 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1208 02:40:26.383692 140718506006400 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1208 02:40:26.383849 140718506006400 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1208 02:40:26.909610 140718506006400 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1208 02:40:26.909771 140718506006400 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1208 02:40:27.610765 140718506006400 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1208 02:40:27.610927 140718506006400 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1208 02:40:28.526678 140718506006400 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1208 02:40:28.526852 140718506006400 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1208 02:40:29.477550 140718506006400 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1208 02:40:29.477734 140718506006400 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1208 02:40:29.751750 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1208 02:40:29.787384 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1208 02:40:29.885289 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1208 02:40:29.885442 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1208 02:40:29.885521 140718506006400 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I1208 02:40:29.887238 140718506006400 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1208 02:40:29.906445 140718506006400 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1208 02:40:29.906565 140718506006400 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1208 02:40:30.186895 140718506006400 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1208 02:40:30.187070 140718506006400 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1208 02:40:30.772335 140718506006400 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1208 02:40:30.772492 140718506006400 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1208 02:40:31.365474 140718506006400 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1208 02:40:31.365636 140718506006400 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1208 02:40:32.213258 140718506006400 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1208 02:40:32.213417 140718506006400 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1208 02:40:33.076031 140718506006400 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1208 02:40:33.076208 140718506006400 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1208 02:40:34.180486 140718506006400 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1208 02:40:34.180646 140718506006400 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1208 02:40:34.538721 140718506006400 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1208 02:40:34.579615 140718506006400 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.39s\n",
            "I1208 02:40:34.926678 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 24.39s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1208 02:40:34.952493 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1208 02:40:34.954102 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1208 02:40:34.954556 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1208 02:40:34.955944 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1208 02:40:34.957191 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1208 02:40:34.957571 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1208 02:40:34.958483 140718506006400 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 30.243s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "id": "32614dcb"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8b1374c6"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ],
      "id": "8b1374c6"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba68f14b",
        "outputId": "cd36738d-027a-40f9-9f65-c45f8e953f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ----------------------\n",
            "absl-py                       1.3.0\n",
            "aeppl                         0.0.33\n",
            "aesara                        2.7.9\n",
            "aiohttp                       3.8.3\n",
            "aiosignal                     1.3.1\n",
            "alabaster                     0.7.12\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.43.0\n",
            "appdirs                       1.4.4\n",
            "arviz                         0.12.1\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.1.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.11.0\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.1\n",
            "blis                          0.7.9\n",
            "bokeh                         2.3.3\n",
            "branca                        0.6.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cachetools                    5.2.0\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.9.24\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.2\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.1.1\n",
            "click                         7.1.2\n",
            "clikit                        0.6.2\n",
            "cloudpickle                   2.2.0\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.0.8\n",
            "colorama                      0.4.6\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.3\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "crashtest                     0.3.1\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda11x                  11.0.0\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.2\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.32\n",
            "daft                          0.0.4\n",
            "dask                          2022.2.1\n",
            "datascience                   0.17.5\n",
            "db-dtypes                     1.0.4\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   2022.2.1\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.7\n",
            "dnspython                     2.2.1\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.334\n",
            "easydict                      1.10\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.1\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         0.9.0\n",
            "etuples                       0.3.8\n",
            "fa2                           0.3.5\n",
            "fastai                        2.7.10\n",
            "fastavro                      1.7.0\n",
            "fastcore                      1.5.27\n",
            "fastdownload                  0.0.7\n",
            "fastdtw                       0.3.4\n",
            "fasteners                     0.18\n",
            "fastjsonschema                2.16.2\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.8.0\n",
            "firebase-admin                5.3.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   22.12.6\n",
            "folium                        0.12.1.post1\n",
            "frozenlist                    1.3.3\n",
            "fsspec                        2022.11.0\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               2.8.2\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   2.15.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.3.6\n",
            "google-cloud-bigquery-storage 2.16.2\n",
            "google-cloud-core             2.3.2\n",
            "google-cloud-datastore        2.9.0\n",
            "google-cloud-firestore        2.7.2\n",
            "google-cloud-language         2.6.1\n",
            "google-cloud-storage          2.5.0\n",
            "google-cloud-translate        3.8.4\n",
            "google-colab                  1.0.0\n",
            "google-crc32c                 1.5.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.4.0\n",
            "googleapis-common-protos      1.57.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      2.0.1\n",
            "grpcio                        1.51.1\n",
            "grpcio-status                 1.48.2\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.17.2\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httpstan                      4.6.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "immutabledict                 2.2.3\n",
            "importlib-metadata            4.13.0\n",
            "importlib-resources           5.10.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2022.2.1\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.25\n",
            "jaxlib                        0.3.25+cuda11.cudnn805\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.2.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter-core                  5.1.0\n",
            "jupyterlab-widgets            3.0.3\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.11.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      14.0.6\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.39.1\n",
            "lmdb                          0.99\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.9.1\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.0.1\n",
            "marshmallow                   3.19.0\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.7.3\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.0.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multidict                     6.0.3\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.7.0\n",
            "netCDF4                       1.6.2\n",
            "networkx                      2.8.8\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      5.7.16\n",
            "numba                         0.56.4\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.21.6\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "object-detection              0.1\n",
            "objsize                       0.5.2\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.5.2.52\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.8.3\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.2\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pastel                        0.2.1\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.10.0\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "platformdirs                  2.5.4\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.8.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.6.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.3\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.5.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.15.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.1\n",
            "proto-plus                    1.22.1\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    9.0.0\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydantic                      1.10.2\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pylev                         1.4.0\n",
            "pymc                          4.1.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.13.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.19.2\n",
            "pysimdjson                    3.2.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        3.3.0\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                7.0.0\n",
            "python-utils                  3.4.5\n",
            "pytz                          2022.6\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post2\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.28.1\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.4.2\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "sacrebleu                     2.2.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.7.3\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.2\n",
            "seaborn                       0.11.2\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.5.post1\n",
            "six                           1.15.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "soundfile                     0.11.0\n",
            "spacy                         3.4.3\n",
            "spacy-legacy                  3.0.10\n",
            "spacy-loggers                 1.0.3\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.44\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.5\n",
            "statsmodels                   0.12.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.1.0\n",
            "tensorboard                   2.11.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.11.0\n",
            "tensorflow-addons             0.18.0\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.11.0\n",
            "tensorflow-gcs-config         2.9.1\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.28.0\n",
            "tensorflow-io-gcs-filesystem  0.28.0\n",
            "tensorflow-metadata           1.11.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-probability        0.17.0\n",
            "tensorflow-text               2.11.0\n",
            "termcolor                     2.1.1\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.11.0\n",
            "tf-slim                       1.1.0\n",
            "thinc                         8.1.5\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2022.10.10\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.13.0+cu116\n",
            "torchaudio                    0.13.0+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.0\n",
            "torchvision                   0.14.0+cu116\n",
            "tornado                       6.0.4\n",
            "tqdm                          4.64.1\n",
            "traitlets                     5.6.0\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typer                         0.7.0\n",
            "typing-extensions             4.4.0\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.5\n",
            "webargs                       8.2.0\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.38.4\n",
            "widgetsnbextension            3.6.1\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        0.20.2\n",
            "xarray-einstats               0.3.0\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.2.0\n",
            "xlwt                          1.3.0\n",
            "yarl                          1.8.2\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.11.0\n",
            "zstandard                     0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ],
      "id": "ba68f14b"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6de03f91",
        "outputId": "9fc28dbe-62a6-444c-a86e-a76c029cc9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-08 02:40:37--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.137.128, 2607:f8b0:4023:c03::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.137.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20518283 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  63.0MB/s    in 0.3s    \n",
            "\n",
            "2022-12-08 02:40:37 (63.0 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "id": "6de03f91"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IWP0ZxWptqt7"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'free', 'id':1}, {'name':'busy', 'id':2}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "id": "IWP0ZxWptqt7"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cG2NRStuttTk"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}\n"
      ],
      "id": "cG2NRStuttTk"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8I69EIgtuNH",
        "outputId": "6b51e3df-59c0-46cf-8d15-ab730cfaadb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "id": "T8I69EIgtuNH"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NucoxJmDt1qe",
        "outputId": "bbe124cd-2d37-436d-9504-edd63fb39bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} \n",
        "\n"
      ],
      "id": "NucoxJmDt1qe"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qcKJyk6bt85Q"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "\n",
        "\n",
        "     "
      ],
      "id": "qcKJyk6bt85Q"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "o989rhFbuLHG"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "id": "o989rhFbuLHG"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eG573Y18zHs5"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "id": "eG573Y18zHs5"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AT9a6KXLzJmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c87844-b6a6-40a0-8f37-25e66ad8e28e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " }, 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2, 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false, 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "config\n"
      ],
      "id": "AT9a6KXLzJmP"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bvibNJ3nzMZ8"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ],
      "id": "bvibNJ3nzMZ8"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uGJs3JS_zOhn"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "id": "uGJs3JS_zOhn"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eXAts4_QzSJx"
      },
      "outputs": [],
      "source": [
        "\n",
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "id": "eXAts4_QzSJx"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TwRpouhRzRmw"
      },
      "outputs": [],
      "source": [
        "\n",
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "id": "TwRpouhRzRmw"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PFm2k0XLzWP5"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
        "\n"
      ],
      "id": "PFm2k0XLzWP5"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOoorV80zbTj",
        "outputId": "886306b8-31b8-41c2-db01-518b9706133f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ],
      "id": "uOoorV80zbTj"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2C1mfEzfnp",
        "outputId": "cc4720c7-a591-4ec8-ad9a-eed3b615e256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 02:40:51.140661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:40:51.140762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:40:51.140778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "2022-12-08 02:40:55.058277: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1208 02:40:55.073841 140666736760704 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I1208 02:40:55.077657 140666736760704 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1208 02:40:55.077804 140666736760704 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1208 02:40:55.104396 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1208 02:40:55.114304 140666736760704 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1208 02:40:55.114477 140666736760704 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1208 02:40:55.114552 140666736760704 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1208 02:40:55.114607 140666736760704 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1208 02:40:55.121439 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1208 02:40:55.138722 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W1208 02:40:55.725180 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1208 02:41:01.454950 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1208 02:41:04.213715 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1208 02:41:05.740502 140666736760704 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.690528 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.693451 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.694468 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.695380 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.698705 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.699619 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.700572 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.701473 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.705613 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1208 02:41:36.706550 140666736760704 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1208 02:41:37.992654 140659082532608 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.437s\n",
            "I1208 02:42:21.574334 140666736760704 model_lib_v2.py:705] Step 100 per-step time 0.437s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14676619,\n",
            " 'Loss/localization_loss': 0.18819423,\n",
            " 'Loss/regularization_loss': 0.15131381,\n",
            " 'Loss/total_loss': 0.4862742,\n",
            " 'learning_rate': 0.0319994}\n",
            "I1208 02:42:21.574644 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.14676619,\n",
            " 'Loss/localization_loss': 0.18819423,\n",
            " 'Loss/regularization_loss': 0.15131381,\n",
            " 'Loss/total_loss': 0.4862742,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.115s\n",
            "I1208 02:42:32.830805 140666736760704 model_lib_v2.py:705] Step 200 per-step time 0.115s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11331096,\n",
            " 'Loss/localization_loss': 0.09116741,\n",
            " 'Loss/regularization_loss': 0.15101524,\n",
            " 'Loss/total_loss': 0.3554936,\n",
            " 'learning_rate': 0.0373328}\n",
            "I1208 02:42:32.831081 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.11331096,\n",
            " 'Loss/localization_loss': 0.09116741,\n",
            " 'Loss/regularization_loss': 0.15101524,\n",
            " 'Loss/total_loss': 0.3554936,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.112s\n",
            "I1208 02:42:44.030093 140666736760704 model_lib_v2.py:705] Step 300 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09905971,\n",
            " 'Loss/localization_loss': 0.058842875,\n",
            " 'Loss/regularization_loss': 0.15066129,\n",
            " 'Loss/total_loss': 0.3085639,\n",
            " 'learning_rate': 0.0426662}\n",
            "I1208 02:42:44.030393 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.09905971,\n",
            " 'Loss/localization_loss': 0.058842875,\n",
            " 'Loss/regularization_loss': 0.15066129,\n",
            " 'Loss/total_loss': 0.3085639,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.113s\n",
            "I1208 02:42:55.292680 140666736760704 model_lib_v2.py:705] Step 400 per-step time 0.113s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.088915884,\n",
            " 'Loss/localization_loss': 0.05029918,\n",
            " 'Loss/regularization_loss': 0.15026332,\n",
            " 'Loss/total_loss': 0.2894784,\n",
            " 'learning_rate': 0.047999598}\n",
            "I1208 02:42:55.292961 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.088915884,\n",
            " 'Loss/localization_loss': 0.05029918,\n",
            " 'Loss/regularization_loss': 0.15026332,\n",
            " 'Loss/total_loss': 0.2894784,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.114s\n",
            "I1208 02:43:06.726901 140666736760704 model_lib_v2.py:705] Step 500 per-step time 0.114s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07943496,\n",
            " 'Loss/localization_loss': 0.047752783,\n",
            " 'Loss/regularization_loss': 0.14981608,\n",
            " 'Loss/total_loss': 0.27700382,\n",
            " 'learning_rate': 0.053333}\n",
            "I1208 02:43:06.727191 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.07943496,\n",
            " 'Loss/localization_loss': 0.047752783,\n",
            " 'Loss/regularization_loss': 0.14981608,\n",
            " 'Loss/total_loss': 0.27700382,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.112s\n",
            "I1208 02:43:17.925126 140666736760704 model_lib_v2.py:705] Step 600 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0796683,\n",
            " 'Loss/localization_loss': 0.03460804,\n",
            " 'Loss/regularization_loss': 0.1493057,\n",
            " 'Loss/total_loss': 0.26358205,\n",
            " 'learning_rate': 0.0586664}\n",
            "I1208 02:43:17.925420 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.0796683,\n",
            " 'Loss/localization_loss': 0.03460804,\n",
            " 'Loss/regularization_loss': 0.1493057,\n",
            " 'Loss/total_loss': 0.26358205,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.112s\n",
            "I1208 02:43:29.172845 140666736760704 model_lib_v2.py:705] Step 700 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060068183,\n",
            " 'Loss/localization_loss': 0.028742358,\n",
            " 'Loss/regularization_loss': 0.14875974,\n",
            " 'Loss/total_loss': 0.23757029,\n",
            " 'learning_rate': 0.0639998}\n",
            "I1208 02:43:29.173122 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.060068183,\n",
            " 'Loss/localization_loss': 0.028742358,\n",
            " 'Loss/regularization_loss': 0.14875974,\n",
            " 'Loss/total_loss': 0.23757029,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.112s\n",
            "I1208 02:43:40.385960 140666736760704 model_lib_v2.py:705] Step 800 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07466086,\n",
            " 'Loss/localization_loss': 0.0644044,\n",
            " 'Loss/regularization_loss': 0.14815304,\n",
            " 'Loss/total_loss': 0.2872183,\n",
            " 'learning_rate': 0.069333196}\n",
            "I1208 02:43:40.386242 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.07466086,\n",
            " 'Loss/localization_loss': 0.0644044,\n",
            " 'Loss/regularization_loss': 0.14815304,\n",
            " 'Loss/total_loss': 0.2872183,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.112s\n",
            "I1208 02:43:51.582065 140666736760704 model_lib_v2.py:705] Step 900 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06648146,\n",
            " 'Loss/localization_loss': 0.025190648,\n",
            " 'Loss/regularization_loss': 0.14749314,\n",
            " 'Loss/total_loss': 0.23916525,\n",
            " 'learning_rate': 0.074666604}\n",
            "I1208 02:43:51.582351 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.06648146,\n",
            " 'Loss/localization_loss': 0.025190648,\n",
            " 'Loss/regularization_loss': 0.14749314,\n",
            " 'Loss/total_loss': 0.23916525,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.112s\n",
            "I1208 02:44:02.797641 140666736760704 model_lib_v2.py:705] Step 1000 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0692651,\n",
            " 'Loss/localization_loss': 0.023133682,\n",
            " 'Loss/regularization_loss': 0.14677228,\n",
            " 'Loss/total_loss': 0.23917106,\n",
            " 'learning_rate': 0.08}\n",
            "I1208 02:44:02.797920 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.0692651,\n",
            " 'Loss/localization_loss': 0.023133682,\n",
            " 'Loss/regularization_loss': 0.14677228,\n",
            " 'Loss/total_loss': 0.23917106,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.124s\n",
            "I1208 02:44:15.195796 140666736760704 model_lib_v2.py:705] Step 1100 per-step time 0.124s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052220505,\n",
            " 'Loss/localization_loss': 0.024312258,\n",
            " 'Loss/regularization_loss': 0.14606051,\n",
            " 'Loss/total_loss': 0.22259328,\n",
            " 'learning_rate': 0.07999918}\n",
            "I1208 02:44:15.196084 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.052220505,\n",
            " 'Loss/localization_loss': 0.024312258,\n",
            " 'Loss/regularization_loss': 0.14606051,\n",
            " 'Loss/total_loss': 0.22259328,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.112s\n",
            "I1208 02:44:26.385702 140666736760704 model_lib_v2.py:705] Step 1200 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05431247,\n",
            " 'Loss/localization_loss': 0.024199707,\n",
            " 'Loss/regularization_loss': 0.14532407,\n",
            " 'Loss/total_loss': 0.22383624,\n",
            " 'learning_rate': 0.079996705}\n",
            "I1208 02:44:26.386015 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.05431247,\n",
            " 'Loss/localization_loss': 0.024199707,\n",
            " 'Loss/regularization_loss': 0.14532407,\n",
            " 'Loss/total_loss': 0.22383624,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.112s\n",
            "I1208 02:44:37.587900 140666736760704 model_lib_v2.py:705] Step 1300 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044011556,\n",
            " 'Loss/localization_loss': 0.019663008,\n",
            " 'Loss/regularization_loss': 0.14456506,\n",
            " 'Loss/total_loss': 0.20823961,\n",
            " 'learning_rate': 0.0799926}\n",
            "I1208 02:44:37.588235 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.044011556,\n",
            " 'Loss/localization_loss': 0.019663008,\n",
            " 'Loss/regularization_loss': 0.14456506,\n",
            " 'Loss/total_loss': 0.20823961,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.112s\n",
            "I1208 02:44:48.787045 140666736760704 model_lib_v2.py:705] Step 1400 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04477038,\n",
            " 'Loss/localization_loss': 0.01825997,\n",
            " 'Loss/regularization_loss': 0.14380257,\n",
            " 'Loss/total_loss': 0.20683292,\n",
            " 'learning_rate': 0.07998685}\n",
            "I1208 02:44:48.787324 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.04477038,\n",
            " 'Loss/localization_loss': 0.01825997,\n",
            " 'Loss/regularization_loss': 0.14380257,\n",
            " 'Loss/total_loss': 0.20683292,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.112s\n",
            "I1208 02:44:59.988490 140666736760704 model_lib_v2.py:705] Step 1500 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044968665,\n",
            " 'Loss/localization_loss': 0.023593996,\n",
            " 'Loss/regularization_loss': 0.14303267,\n",
            " 'Loss/total_loss': 0.21159533,\n",
            " 'learning_rate': 0.07997945}\n",
            "I1208 02:44:59.988835 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.044968665,\n",
            " 'Loss/localization_loss': 0.023593996,\n",
            " 'Loss/regularization_loss': 0.14303267,\n",
            " 'Loss/total_loss': 0.21159533,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.112s\n",
            "I1208 02:45:11.176870 140666736760704 model_lib_v2.py:705] Step 1600 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05283362,\n",
            " 'Loss/localization_loss': 0.019015294,\n",
            " 'Loss/regularization_loss': 0.1422718,\n",
            " 'Loss/total_loss': 0.21412072,\n",
            " 'learning_rate': 0.079970405}\n",
            "I1208 02:45:11.177191 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.05283362,\n",
            " 'Loss/localization_loss': 0.019015294,\n",
            " 'Loss/regularization_loss': 0.1422718,\n",
            " 'Loss/total_loss': 0.21412072,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.112s\n",
            "I1208 02:45:22.353142 140666736760704 model_lib_v2.py:705] Step 1700 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05393812,\n",
            " 'Loss/localization_loss': 0.021410465,\n",
            " 'Loss/regularization_loss': 0.14151186,\n",
            " 'Loss/total_loss': 0.21686044,\n",
            " 'learning_rate': 0.07995972}\n",
            "I1208 02:45:22.353455 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.05393812,\n",
            " 'Loss/localization_loss': 0.021410465,\n",
            " 'Loss/regularization_loss': 0.14151186,\n",
            " 'Loss/total_loss': 0.21686044,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.112s\n",
            "I1208 02:45:33.553359 140666736760704 model_lib_v2.py:705] Step 1800 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051884197,\n",
            " 'Loss/localization_loss': 0.015005451,\n",
            " 'Loss/regularization_loss': 0.14074191,\n",
            " 'Loss/total_loss': 0.20763156,\n",
            " 'learning_rate': 0.0799474}\n",
            "I1208 02:45:33.553630 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.051884197,\n",
            " 'Loss/localization_loss': 0.015005451,\n",
            " 'Loss/regularization_loss': 0.14074191,\n",
            " 'Loss/total_loss': 0.20763156,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.112s\n",
            "I1208 02:45:44.742540 140666736760704 model_lib_v2.py:705] Step 1900 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.042310566,\n",
            " 'Loss/localization_loss': 0.021521194,\n",
            " 'Loss/regularization_loss': 0.13998415,\n",
            " 'Loss/total_loss': 0.2038159,\n",
            " 'learning_rate': 0.07993342}\n",
            "I1208 02:45:44.742812 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.042310566,\n",
            " 'Loss/localization_loss': 0.021521194,\n",
            " 'Loss/regularization_loss': 0.13998415,\n",
            " 'Loss/total_loss': 0.2038159,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.112s\n",
            "I1208 02:45:55.921421 140666736760704 model_lib_v2.py:705] Step 2000 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05107129,\n",
            " 'Loss/localization_loss': 0.013121873,\n",
            " 'Loss/regularization_loss': 0.1392277,\n",
            " 'Loss/total_loss': 0.20342086,\n",
            " 'learning_rate': 0.07991781}\n",
            "I1208 02:45:55.921701 140666736760704 model_lib_v2.py:708] {'Loss/classification_loss': 0.05107129,\n",
            " 'Loss/localization_loss': 0.013121873,\n",
            " 'Loss/regularization_loss': 0.1392277,\n",
            " 'Loss/total_loss': 0.20342086,\n",
            " 'learning_rate': 0.07991781}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ],
      "id": "Eo2C1mfEzfnp"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RlpWIO3ZzoDg"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
        "\n"
      ],
      "id": "RlpWIO3ZzoDg"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KQlrYpST31fT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e3dfbf-566d-4e70-857e-72d932540759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/ssd_mobilenet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ],
      "id": "KQlrYpST31fT"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HwFS106Z3322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af44720e-2442-4e72-9063-f81fb03f85eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 02:46:01.296054: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:46:01.296189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:46:01.296209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1208 02:46:04.416330 139968524281728 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I1208 02:46:04.416543 139968524281728 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1208 02:46:04.416610 139968524281728 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1208 02:46:04.416674 139968524281728 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1208 02:46:04.416774 139968524281728 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-12-08 02:46:05.230416: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I1208 02:46:05.281859 139968524281728 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I1208 02:46:05.282081 139968524281728 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1208 02:46:05.282168 139968524281728 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1208 02:46:05.282230 139968524281728 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1208 02:46:05.286795 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1208 02:46:05.305394 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W1208 02:46:05.896776 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1208 02:46:08.926753 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1208 02:46:09.973418 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet\n",
            "I1208 02:46:12.361404 139968524281728 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet\n",
            "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/ssd_mobilenet/ckpt-3\n",
            "I1208 02:46:12.362401 139968524281728 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/ssd_mobilenet/ckpt-3\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1208 02:46:35.825899 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I1208 02:46:35.961627 139968524281728 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1208 02:46:36.102883 139968524281728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Performing evaluation on 11 images.\n",
            "I1208 02:46:38.378746 139968524281728 coco_evaluation.py:293] Performing evaluation on 11 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1208 02:46:38.379086 139968524281728 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1208 02:46:38.379785 139968524281728 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.783\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.679\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "INFO:tensorflow:Eval metrics at step 2000\n",
            "I1208 02:46:38.645875 139968524281728 model_lib_v2.py:1015] Eval metrics at step 2000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.677987\n",
            "I1208 02:46:38.709342 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.677987\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.998954\n",
            "I1208 02:46:38.710866 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.998954\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.783037\n",
            "I1208 02:46:38.712198 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.783037\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I1208 02:46:38.713432 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.617708\n",
            "I1208 02:46:38.714677 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.617708\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.748926\n",
            "I1208 02:46:38.716370 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.748926\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.140152\n",
            "I1208 02:46:38.717623 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.140152\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.630303\n",
            "I1208 02:46:38.718862 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.630303\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.733874\n",
            "I1208 02:46:38.720059 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.733874\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I1208 02:46:38.721098 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.679315\n",
            "I1208 02:46:38.722319 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.679315\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.781352\n",
            "I1208 02:46:38.723562 139968524281728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.781352\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.081435\n",
            "I1208 02:46:38.724491 139968524281728 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.081435\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.150811\n",
            "I1208 02:46:38.725432 139968524281728 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.150811\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.139220\n",
            "I1208 02:46:38.726372 139968524281728 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.139220\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.371467\n",
            "I1208 02:46:38.727321 139968524281728 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.371467\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ],
      "id": "HwFS106Z3322"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-30nWZ63667"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "id": "K-30nWZ63667"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vn-oSrgS389a"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "id": "vn-oSrgS389a"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "C1uQtasU3-79"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "C1uQtasU3-79"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "yQFUpHis4BiH"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "id": "yQFUpHis4BiH"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yq9FKeqe4DN7"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'demo', '1.jpg')"
      ],
      "id": "yq9FKeqe4DN7"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9KnNDPsTITs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "7039d9aa-a154-4d4f-8761-519366369cc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=25,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n"
      ],
      "id": "9KnNDPsTITs8"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q5RX5VWV_Cp",
        "outputId": "c6616de6-34dc-46bf-b5fb-b247e3c90059"
      },
      "id": "5q5RX5VWV_Cp",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.2.52\n",
            "Uninstalling opencv-python-headless-4.5.2.52:\n",
            "  Successfully uninstalled opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ViEEJcKvjBf_"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break\n",
        "\n"
      ],
      "id": "ViEEJcKvjBf_"
    },
    {
      "cell_type": "code",
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ],
      "metadata": {
        "id": "1S1QR-MTQgJe"
      },
      "id": "1S1QR-MTQgJe",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "imXZBdyVnI8G"
      },
      "id": "imXZBdyVnI8G",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(command)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLCiqUAGnLGH",
        "outputId": "98666b2f-b723-4194-a035-2cbeb99fbd52"
      },
      "id": "mLCiqUAGnLGH",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py  --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/ssd_mobilenet --output_directory=Tensorflow/workspace/models/ssd_mobilenet/tfliteexport\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FDZGeK2nN-Q",
        "outputId": "dcc99647-5276-4293-9103-8609c4f805d3"
      },
      "id": "8FDZGeK2nN-Q",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 02:48:45.706709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:48:45.706839: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:48:45.706858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "2022-12-08 02:48:48.561063: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W1208 02:48:54.082452 139657360201600 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f036c3ffee0>, because it is not built.\n",
            "W1208 02:48:59.728945 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f036c3ffee0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c0b0b20>, because it is not built.\n",
            "W1208 02:48:59.998172 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c0b0b20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c1c4e20>, because it is not built.\n",
            "W1208 02:48:59.998365 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c1c4e20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c1c4f70>, because it is not built.\n",
            "W1208 02:48:59.998457 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c1c4f70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c0b8c70>, because it is not built.\n",
            "W1208 02:48:59.998526 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c0b8c70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c265be0>, because it is not built.\n",
            "W1208 02:48:59.998592 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c265be0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c265ca0>, because it is not built.\n",
            "W1208 02:48:59.998656 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c265ca0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c265550>, because it is not built.\n",
            "W1208 02:48:59.998716 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c265550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c185dc0>, because it is not built.\n",
            "W1208 02:48:59.998774 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c185dc0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b4d2ee0>, because it is not built.\n",
            "W1208 02:48:59.998837 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b4d2ee0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c1f4df0>, because it is not built.\n",
            "W1208 02:48:59.998905 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f036c1f4df0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c0746a0>, because it is not built.\n",
            "W1208 02:48:59.998965 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c0746a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c074dc0>, because it is not built.\n",
            "W1208 02:48:59.999026 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c074dc0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c0ed4c0>, because it is not built.\n",
            "W1208 02:48:59.999089 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c0ed4c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c1405b0>, because it is not built.\n",
            "W1208 02:48:59.999160 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c1405b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c067460>, because it is not built.\n",
            "W1208 02:48:59.999221 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c067460>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c0678b0>, because it is not built.\n",
            "W1208 02:48:59.999283 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c0678b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c0703d0>, because it is not built.\n",
            "W1208 02:48:59.999345 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c0703d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c0706d0>, because it is not built.\n",
            "W1208 02:48:59.999404 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c0706d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b1fe970>, because it is not built.\n",
            "W1208 02:48:59.999468 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b1fe970>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b1fe8b0>, because it is not built.\n",
            "W1208 02:48:59.999534 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b1fe8b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b582e20>, because it is not built.\n",
            "W1208 02:48:59.999595 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b582e20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b2053d0>, because it is not built.\n",
            "W1208 02:48:59.999653 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b2053d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b205520>, because it is not built.\n",
            "W1208 02:48:59.999711 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b205520>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b205b20>, because it is not built.\n",
            "W1208 02:48:59.999776 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b205b20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b205ee0>, because it is not built.\n",
            "W1208 02:48:59.999834 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b205ee0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b205fd0>, because it is not built.\n",
            "W1208 02:48:59.999891 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b205fd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b1de490>, because it is not built.\n",
            "W1208 02:48:59.999948 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b1de490>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b1de730>, because it is not built.\n",
            "W1208 02:49:00.000014 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b1de730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b592c40>, because it is not built.\n",
            "W1208 02:49:00.000073 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b592c40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c227a90>, because it is not built.\n",
            "W1208 02:49:00.000132 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c227a90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b685c10>, because it is not built.\n",
            "W1208 02:49:00.000229 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b685c10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b6857c0>, because it is not built.\n",
            "W1208 02:49:00.000382 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b6857c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b6859a0>, because it is not built.\n",
            "W1208 02:49:00.000451 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b6859a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b6854c0>, because it is not built.\n",
            "W1208 02:49:00.000516 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b6854c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b2ffdc0>, because it is not built.\n",
            "W1208 02:49:00.000580 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b2ffdc0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b2ff8b0>, because it is not built.\n",
            "W1208 02:49:00.000642 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b2ff8b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c1113d0>, because it is not built.\n",
            "W1208 02:49:00.000701 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c1113d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b68a5b0>, because it is not built.\n",
            "W1208 02:49:00.000769 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b68a5b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b68a610>, because it is not built.\n",
            "W1208 02:49:00.000831 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b68a610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b68a580>, because it is not built.\n",
            "W1208 02:49:00.000890 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b68a580>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b68a520>, because it is not built.\n",
            "W1208 02:49:00.000952 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f033b68a520>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b68a040>, because it is not built.\n",
            "W1208 02:49:00.001015 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f033b68a040>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c23e8b0>, because it is not built.\n",
            "W1208 02:49:00.012577 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f036c23e8b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c23ebb0>, because it is not built.\n",
            "W1208 02:49:00.012727 139657360201600 save_impl.py:66] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f036c23ebb0>, because it is not built.\n",
            "W1208 02:49:16.447263 139657360201600 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/ssd_mobilenet/tfliteexport/saved_model/assets\n",
            "I1208 02:49:21.793115 139657360201600 builder_impl.py:797] Assets written to: Tensorflow/workspace/models/ssd_mobilenet/tfliteexport/saved_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ],
      "metadata": {
        "id": "nYiCVZgDnQ6i"
      },
      "id": "nYiCVZgDnQ6i",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ],
      "metadata": {
        "id": "YjFbF7MjnTCx"
      },
      "id": "YjFbF7MjnTCx",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nqIE5ZfnViI",
        "outputId": "d9633270-9850-4653-a495-b79696d5b7bc"
      },
      "id": "-nqIE5ZfnViI",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tflite_convert --saved_model_dir=Tensorflow/workspace/models/ssd_mobilenet/tfliteexport/saved_model --output_file=Tensorflow/workspace/models/ssd_mobilenet/tfliteexport/saved_model/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xYWlX81nXHd",
        "outputId": "66883f13-0e49-470d-ac35-4e7db33c5b8d"
      },
      "id": "9xYWlX81nXHd",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-08 02:50:03.130944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:50:03.131064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-08 02:50:03.131083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-12-08 02:50:05.730898: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-12-08 02:50:14.924484: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
            "2022-12-08 02:50:14.924544: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}\n"
      ],
      "metadata": {
        "id": "B9Z8DPDvnamX"
      },
      "id": "B9Z8DPDvnamX",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7zGVBabncWW",
        "outputId": "c29726fe-337c-4b21-d0ab-3089c7ee2b89"
      },
      "id": "p7zGVBabncWW",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "15a24df50aad89762b44c55dbfccf1a441e09a49c35bfde0e81545326154b02b"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}